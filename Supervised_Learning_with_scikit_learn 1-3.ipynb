{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Supervised Learning with scikit-learn",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN66XVIgnDkrjjrqAUQbSzw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShairaRubante/FTW/blob/main/Supervised_Learning_with_scikit_learn%201-3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Machine Learning with scikit-learn**\n",
        "\n",
        "**Machine Learning is the process whereby:**\n",
        "*   Computers are given the ability to learn to make decisions from data\n",
        "*   Without explicitly being programmed!\n",
        "*   **Example:** Learning to preditct whether an email is spam or not spam knowing the content and sender\n",
        "*   **Example:** Learning to cluster books into different categories based on the words they contain, then assigning any new book to one of the existing clusters \n",
        "\n",
        "\n",
        "**Unsupervised Learning**\n",
        "*   Uncovering hidden patterns from unlabeled data\n",
        "*   **Example** Grouping customers into distinct categories based on their purchasing behavior\n",
        "\n",
        "**Supervised Learning**\n",
        "*   The predicted value are known\n",
        "*   **Aim:** Predict the target value of unseen data, given the features\n",
        "*   **Example** Predicting the player's position using their points per game\n",
        "\n",
        "**Types of Supervised Learning**\n",
        "*   Classification\n",
        "*   Regression\n",
        "\n",
        "\n",
        "**Classification Supervised Learning**\n",
        "*   Target variable consists of categories\n",
        "*   **Example** Predict if the bank transaction is fraudulent or not. There are two categories, 'Fraudulent'and 'Not fraudulent.\n",
        "\n",
        "**Regression Supervised Learning**\n",
        "*   Target variable is continuous\n",
        "*   **Example** Use number of bedrooms and size of the property to predict the price of the property.\n",
        "\n",
        "**Naming conventions**\n",
        "*   Feature = predictor variable = independent variable\n",
        "*   Target variable = dependent variable = response variable\n",
        "\n",
        "**Requirements before you do supervised learning**\n",
        "*   No missing values\n",
        "*   Data must be in numeric format\n",
        "*   Data stored in pandas DataFrame or NumPy Arrat\n",
        "*   **Remember** Perform EDA first to ensure data is in correct format\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fdlm6JoopoVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install scikit-learn in COlab\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlqaTD2jrC92",
        "outputId": "62550980-f7d0-49d0-9b81-1dd15fd1ee52"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scikit-learn syntax\n",
        "from sklearn.module import Model\n",
        "model - Model()\n",
        "mode.fit(X, y)\n",
        "predictions = model.predict(X_new)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "kdZEMLOqxACa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary classification\n",
        "In the video, you saw that there are two types of supervised learning — classification and regression. Recall that binary classification is used to predict a target variable that has only two labels, typically represented numerically with a zero or a one.\n",
        "\n",
        "A dataset, churn_df, has been preloaded for you in the console.\n",
        "\n",
        "Your task is to examine the data and choose which column could be the target variable for binary classification.\n",
        "\n",
        "\n",
        "\n",
        "**Possible Answers**\n",
        "*   customer_service_calls\n",
        "*   total_night_charge\n",
        "*   **churn**\n",
        "*   account_length\n",
        "\n"
      ],
      "metadata": {
        "id": "tqKz0bOGyyu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The classification challenge\n",
        "\n",
        "**Classifying labels of unseen data**\n",
        "1.   Build a model\n",
        "2.   Model learns from the labeled data we pass it\n",
        "3.   Pass unlabeled data to the model as input\n",
        "4.   Model predicts the labels of the unseen data\n",
        "\n",
        "Labeled data = Training data\n",
        "\n",
        "**k-Nearest Neighbors**\n",
        "It predicts the label of a data point by\n",
        "*   Looking at the k closest labeled data points\n",
        "*   Taking a majority vote\n",
        "\n",
        "If [k= 3](https://github.com/ShairaRubante/FTW/blob/main/k%20%3D3.png) we can classify the black dot as red\n",
        "\n",
        "If [k= 5](https://github.com/ShairaRubante/FTW/blob/main/k%3D5.png) we can classify the black dot as blue\n",
        "\n",
        "[**KNN Intuition**](https://github.com/ShairaRubante/FTW/blob/main/KNN%20Intuition.png)\n",
        "*   All in grey are predicted to churn\n",
        "*   All in red background are predicted to not churn\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dkwC113uztEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import all necessary modules\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "tgzxVBm63EJY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload dataset\n",
        "url = \"https://raw.githubusercontent.com/ShairaRubante/FTW/main/telecom_churn_clean.csv\"\n",
        "churn = pd.read_csv(url)\n",
        "display(churn.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "AN2JmheQ4usq",
        "outputId": "970f60f2-0c41-488c-dd2f-7d1f32a9014c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Unnamed: 0  account_length  area_code  international_plan  voice_mail_plan  \\\n",
              "0           0             128        415                   0                1   \n",
              "1           1             107        415                   0                1   \n",
              "2           2             137        415                   0                0   \n",
              "3           3              84        408                   1                0   \n",
              "4           4              75        415                   1                0   \n",
              "\n",
              "   number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
              "0                     25              265.1              110   \n",
              "1                     26              161.6              123   \n",
              "2                      0              243.4              114   \n",
              "3                      0              299.4               71   \n",
              "4                      0              166.7              113   \n",
              "\n",
              "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
              "0             45.07              197.4               99             16.78   \n",
              "1             27.47              195.5              103             16.62   \n",
              "2             41.38              121.2              110             10.30   \n",
              "3             50.90               61.9               88              5.26   \n",
              "4             28.34              148.3              122             12.61   \n",
              "\n",
              "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
              "0                244.7                 91               11.01   \n",
              "1                254.4                103               11.45   \n",
              "2                162.6                104                7.32   \n",
              "3                196.9                 89                8.86   \n",
              "4                186.9                121                8.41   \n",
              "\n",
              "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
              "0                10.0                 3               2.70   \n",
              "1                13.7                 3               3.70   \n",
              "2                12.2                 5               3.29   \n",
              "3                 6.6                 7               1.78   \n",
              "4                10.1                 3               2.73   \n",
              "\n",
              "   customer_service_calls  churn  \n",
              "0                       1      0  \n",
              "1                       1      0  \n",
              "2                       0      0  \n",
              "3                       2      0  \n",
              "4                       3      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-464ac892-46dc-4f0a-962d-48a2dbf2e7a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>account_length</th>\n",
              "      <th>area_code</th>\n",
              "      <th>international_plan</th>\n",
              "      <th>voice_mail_plan</th>\n",
              "      <th>number_vmail_messages</th>\n",
              "      <th>total_day_minutes</th>\n",
              "      <th>total_day_calls</th>\n",
              "      <th>total_day_charge</th>\n",
              "      <th>total_eve_minutes</th>\n",
              "      <th>total_eve_calls</th>\n",
              "      <th>total_eve_charge</th>\n",
              "      <th>total_night_minutes</th>\n",
              "      <th>total_night_calls</th>\n",
              "      <th>total_night_charge</th>\n",
              "      <th>total_intl_minutes</th>\n",
              "      <th>total_intl_calls</th>\n",
              "      <th>total_intl_charge</th>\n",
              "      <th>customer_service_calls</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>265.1</td>\n",
              "      <td>110</td>\n",
              "      <td>45.07</td>\n",
              "      <td>197.4</td>\n",
              "      <td>99</td>\n",
              "      <td>16.78</td>\n",
              "      <td>244.7</td>\n",
              "      <td>91</td>\n",
              "      <td>11.01</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>107</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>161.6</td>\n",
              "      <td>123</td>\n",
              "      <td>27.47</td>\n",
              "      <td>195.5</td>\n",
              "      <td>103</td>\n",
              "      <td>16.62</td>\n",
              "      <td>254.4</td>\n",
              "      <td>103</td>\n",
              "      <td>11.45</td>\n",
              "      <td>13.7</td>\n",
              "      <td>3</td>\n",
              "      <td>3.70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>137</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>243.4</td>\n",
              "      <td>114</td>\n",
              "      <td>41.38</td>\n",
              "      <td>121.2</td>\n",
              "      <td>110</td>\n",
              "      <td>10.30</td>\n",
              "      <td>162.6</td>\n",
              "      <td>104</td>\n",
              "      <td>7.32</td>\n",
              "      <td>12.2</td>\n",
              "      <td>5</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>84</td>\n",
              "      <td>408</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>299.4</td>\n",
              "      <td>71</td>\n",
              "      <td>50.90</td>\n",
              "      <td>61.9</td>\n",
              "      <td>88</td>\n",
              "      <td>5.26</td>\n",
              "      <td>196.9</td>\n",
              "      <td>89</td>\n",
              "      <td>8.86</td>\n",
              "      <td>6.6</td>\n",
              "      <td>7</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>75</td>\n",
              "      <td>415</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>166.7</td>\n",
              "      <td>113</td>\n",
              "      <td>28.34</td>\n",
              "      <td>148.3</td>\n",
              "      <td>122</td>\n",
              "      <td>12.61</td>\n",
              "      <td>186.9</td>\n",
              "      <td>121</td>\n",
              "      <td>8.41</td>\n",
              "      <td>10.1</td>\n",
              "      <td>3</td>\n",
              "      <td>2.73</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-464ac892-46dc-4f0a-962d-48a2dbf2e7a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-464ac892-46dc-4f0a-962d-48a2dbf2e7a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-464ac892-46dc-4f0a-962d-48a2dbf2e7a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use scikit-learn to fit a classifier**"
      ],
      "metadata": {
        "id": "auiVBQxK6hko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use scikit-learn to fit a classifier\n",
        "x = churn[[\"total_day_charge\",\"total_eve_charge\"]].values\n",
        "y=churn[\"churn\"].values\n",
        "print(x.shape,y.shape)\n",
        "knn = KNeighborsClassifier(n_neighbors=15)\n",
        "knn.fit(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "FivMdExJ5spA",
        "outputId": "f501bec2-b566-4231-b6b7-a407bee90b08"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5ab0a05a612a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Use scikit-learn to fit a classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchurn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"total_day_charge\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"total_eve_charge\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchurn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"churn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'churn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicting on Unlabled Data**"
      ],
      "metadata": {
        "id": "Y54zQaPt6sXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_new = np.array([[56.8,17.5],\n",
        "                  [24.4,24.1],\n",
        "                  [50.1,10.9]])\n",
        "print(x_new.shape)\n",
        "predictions = knn.predict(x_new)\n",
        "print(\"Predictions:{}\".format(predictions))"
      ],
      "metadata": {
        "id": "HQjRd08O6f-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Measuring Model Performance\n",
        "\n",
        "**Accuracy**\n",
        "*   Commonly used metric\n",
        "*   Accuracy = correct predictions/ total observations\n",
        "*   We could compute accuracy on the data used to fit the classifier\n",
        "*   Performance NOT indicative of ability to generalize\n",
        "\n",
        "**Computing Accuracy**\n",
        "\n",
        "\n",
        "*   Split data to Training Set & Test Set\n",
        "*   Fit/train classifier on training set\n",
        "*   Calculate accuracy using Test Set\n",
        "\n"
      ],
      "metadata": {
        "id": "PLqJfpNs9XEW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train/test split**\n",
        "\n"
      ],
      "metadata": {
        "id": "kAH0y2LH-W0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = churn.drop(\"churn\", axis=1).values\n",
        "y = churn[\"churn\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=21, stratify = y)\n",
        "knn = KNeighborsClassifier(n_neighbors =6)\n",
        "knn.fit(X_train, y_train)\n",
        "print(knn.score(X_test,y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4eTXVr6-WDn",
        "outputId": "64446cdf-17e0-42f4-887a-038e127a4831"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Complexity**\n",
        "*  Larger k = less complex model = cause underfitting\n",
        "*  Smaller k = more complex model = can lead to overfitting\n"
      ],
      "metadata": {
        "id": "y5h8wCC1_k4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model complexity and over/underfitting**\n"
      ],
      "metadata": {
        "id": "6yIlBDHOAIVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neighbors = np.arange(1,26)\n",
        "train_accuracies ={}\n",
        "test_accuracies ={}\n",
        "\n",
        "for neighbor in neighbors:\n",
        "  knn = KNeighborsClassifier(n_neighbors=neighbor)\n",
        "  knn.fit(X_train,y_train)\n",
        "  train_accuracies[neighbor]= knn.score(X_train, y_train)\n",
        "  test_accuracies[neighbor]= knn.score(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "oToyu5HxAH6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting our results**\n"
      ],
      "metadata": {
        "id": "xJfj2SGlA2t-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize =(8,6))\n",
        "plt.title(\"KNN: Varying Number of Neighbors\")\n",
        "plt.plot(neighbors, train_accuracies.values(),label=\"Training Accuracy\")\n",
        "plt.plot(neighbors, test_accuracies.values(),label=\"Testing Accuracy\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Number of Neighbors\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "#Will show Mdel Complexity Curve"
      ],
      "metadata": {
        "id": "FjAvGHfpA_fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise:** Train/test split + computing accuracy\n",
        "\n",
        "Now that you have learned about the importance of splitting your data into training and test sets, it's time to practice doing this on the churn_df dataset!\n",
        "\n",
        "NumPy arrays have been created for you containing the features as X and the target variable as y. You will split them into training and test sets, fit a KNN classifier to the training data, and then compute its accuracy on the test data using the .score() method.\n",
        "\n",
        "Instructions\n",
        "*  Import train_test_split from sklearn.model_selection.\n",
        "*  Split X and y into training and test sets, setting test_size equal to 20%, random_state to 42, and ensuring the target label proportions reflect that of the original dataset.\n",
        "*  Fit the knn model to the training data.\n",
        "*  Compute and print the model's accuracy for the test data\n",
        "\n"
      ],
      "metadata": {
        "id": "7a6XcgIABmfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify = y)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "knn = KNeighborsClassifier(n_neighbors =6)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Print the accuracy\n",
        "print(knn.score(X_test,y_test))"
      ],
      "metadata": {
        "id": "ZRgQZICcA_mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise:** Overfitting and underfitting\n",
        "\n",
        "\n",
        "Interpreting model complexity is a great way to evaluate performance when utilizing supervised learning. Your aim is to produce a model that can interpret the relationship between features and the target variable, as well as generalize well when exposed to new observations.\n",
        "\n",
        "You will generate accuracy scores for the training and test sets using a KNN classifier with different n_neighbor values, which you will plot in the next exercise.\n",
        "\n",
        "The training and test sets have been created from the churn_df dataset and preloaded as X_train, X_test, y_train, and y_test.\n",
        "\n",
        "In addition, KNeighborsClassifier has been imported for you along with numpy as np.\n",
        "\n",
        "Instructions\n",
        "\n",
        "* Create neighbors as a numpy array of values from 1 up to and including 12.\n",
        "* Instantiate a KNN classifier, with the number of neighbors equal to the neighbor iterator.\n",
        "* Fit the model to the training data.\n",
        "* Calculate accuracy scores for the training set and test set separately using the .score() method, and assign the results to the index of the train_accuracies and test_accuracies dictionaries, respectively."
      ],
      "metadata": {
        "id": "Lmc8TL4pDa7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create neighbors\n",
        "neighbors = np.arange(1, 13)\n",
        "train_accuracies = {}\n",
        "test_accuracies = {}\n",
        "\n",
        "for neighbor in neighbors:\n",
        "  \n",
        "\t# Set up a KNN Classifier\n",
        "\tknn = KNeighborsClassifier(n_neighbors=neighbor)\n",
        "  \n",
        "\t# Fit the model\n",
        "\tknn.fit(X_train,y_train)\n",
        "  \n",
        "\t# Compute accuracy\n",
        "\ttrain_accuracies[neighbor]= knn.score(X_train, y_train)\n",
        "\ttest_accuracies[neighbor]= knn.score(X_test, y_test)\n",
        "print(neighbors, '\\n', train_accuracies, '\\n', test_accuracies)"
      ],
      "metadata": {
        "id": "Urf28W-ADsht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise:** Visualizing model complexity\n",
        "\n",
        "Now you have calculated the accuracy of the KNN model on the training and test sets using various values of n_neighbors, you can create a model complexity curve to visualize how performance changes as the model becomes less complex!\n",
        "\n",
        "The variables neighbors, train_accuracies, and test_accuracies, which you generated in the previous exercise, have all been preloaded for you. You will plot the results to aid in finding the optimal number of neighbors for your model.\n",
        "\n",
        "Instructions\n",
        "\n",
        "*  Add a title \"KNN: Varying Number of Neighbors\".\n",
        "*  Plot the .values() method of train_accuracies on the y-axis against neighbors on the x-axis, with a label of \"Training Accuracy\".\n",
        "*  Plot the .values() method of test_accuracies on the y-axis against neighbors on the x-axis, with a label of \"Testing Accuracy\".\n",
        "*  Display the plot."
      ],
      "metadata": {
        "id": "qE0TIEI7D1I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a title\n",
        "plt.title(\"KNN: Varying Number of Neighbors\")\n",
        "\n",
        "# Plot training accuracies\n",
        "plt.plot(neighbors, train_accuracies.values(),label=\"Training Accuracy\")\n",
        "\n",
        "# Plot test accuracies\n",
        "plt.plot(neighbors, test_accuracies.values(),label=\"Testing Accuracy\")\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"Number of Neighbors\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kLXilcsgEheQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Introduction to regression**\n",
        "\n",
        "Always has a continous value. We will use dataset for predicting blood glucose level.\n",
        "\n"
      ],
      "metadata": {
        "id": "DNjAoDCQGYDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicting Blood Glucose Level**\n"
      ],
      "metadata": {
        "id": "IRtFbn09TLev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/ShairaRubante/FTW/main/diabetes_clean.csv\"\n",
        "diabetes_df = pd.read_csv(url)\n",
        "display(diabetes_df.head())"
      ],
      "metadata": {
        "id": "SjkZ9jeiS6Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating features and target arrays**"
      ],
      "metadata": {
        "id": "Tb1-bP6dThUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = diabetes_df.drop(\"glucose\", axis =1).values\n",
        "y = diabetes_df[\"glucose\"].values\n",
        "\n",
        "#to confirm if both x and y are numpy arrays\n",
        "print(type(x),type(y))"
      ],
      "metadata": {
        "id": "hDV7FgwKTkTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Making predictions from a single feature**"
      ],
      "metadata": {
        "id": "Tud2CYpeUEHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_bmi = X[:,3]\n",
        "print(y.shape,X_bmi.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "l-i8xY2bUDmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape\n",
        "X_bmi = X_bmi.reshape(-1,1)\n",
        "print(X_bmi.shape)\n"
      ],
      "metadata": {
        "id": "QVflX5saUpD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting glucose vs body mass index**"
      ],
      "metadata": {
        "id": "g2u34F_0Uwxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X_bmi,y)\n",
        "plt.ylabel(\"Blood Glucose (mg/dl)\")\n",
        "plt.xlabel(\"Body Mass Index\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5JRml8pQU0G5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting a regression model**"
      ],
      "metadata": {
        "id": "cjclLAaTVV8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_bmi, y)\n",
        "predictions = reg.predict(X_bmi)\n",
        "plt.scatter(X_bmi, y)\n",
        "plt.plot(X_bmi, predictions)\n",
        "plt.ylabel(\"Blood Glucose (mg/dl)\")\n",
        "plt.xlabel(\"Body Mass Index\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hKCW6VI9VVjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Exercise:** Creating features\n",
        "In this chapter, you will work with a dataset called sales_df, which contains information on advertising campaign expenditure across different media types, and the number of dollars generated in sales for the respective campaign. The dataset has been preloaded for you. Here are the first two rows:\n",
        "\n",
        "     tv        radio      social_media    sales\n",
        "     13000.0   9237.76    2409.57         46677.90\n",
        "     41000.0   15886.45   2913.41         150177.83\n",
        "\n",
        "\n",
        "You will use the advertising expenditure as features to predict sales values, initially working with the \"radio\" column. However, before you make any predictions you will need to create the feature and target arrays, reshaping them to the correct format for scikit-learn.\n",
        "\n",
        "Instructions\n",
        "1.  Create X, an array of the values from the sales_df DataFrame's \"radio\" column.\n",
        "2.  Create y, an array of the values from the sales_df DataFrame's \"sales\" column.\n",
        "3.  Reshape X into a two-dimensional NumPy array.\n",
        "4.  Print the shape of X and y.\n"
      ],
      "metadata": {
        "id": "WLdRs-FWX8YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import sales_df\n",
        "url = \"https://raw.githubusercontent.com/ShairaRubante/FTW/main/advertising_and_sales_clean.csv\"\n",
        "sales_df = pd.read_csv(url)\n",
        "display(sales_df.head())"
      ],
      "metadata": {
        "id": "kGztN8x8Y6IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create X from the radio column's values\n",
        "X = sales_df[\"radio\"].values\n",
        "\n",
        "# Create y from the sales column's values\n",
        "y = sales_df[\"sales\"].values\n",
        "\n",
        "# Reshape X\n",
        "X = X.reshape(-1, 1)\n",
        "\n",
        "# Check the shape of the features and targets\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "0yKQwu4NYlCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Exercise:** Building a linear regression model\n",
        "Now you have created your feature and target arrays, you will train a linear regression model on all feature and target values.\n",
        "\n",
        "As the goal is to assess the relationship between the feature and target values there is no need to split the data into training and test sets.\n",
        "\n",
        "X and y have been preloaded for you as follows:\n",
        "\n",
        "y = sales_df[\"sales\"].values\n",
        "\n",
        "X = sales_df[\"radio\"].values.reshape(-1, 1)\n",
        "\n",
        "Instructions\n",
        "1.  Import LinearRegression.\n",
        "2.  Instantiate a linear regression model.\n",
        "3.  Predict sales values using X, storing as predictions."
      ],
      "metadata": {
        "id": "R32MC8ciZJ72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import LinearRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create the model\n",
        "reg = LinearRegression()\n",
        "\n",
        "# Fit the model to the data\n",
        "reg.fit(X, y)\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "predictions = reg.predict(X)\n",
        "\n",
        "print(predictions[:5])"
      ],
      "metadata": {
        "id": "u8lPylzAZ54w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Exercise:** Visualizing a linear regression model\n",
        "Now you have built your linear regression model and trained it using all available observations, you can visualize how well the model fits the data. This allows you to interpret the relationship between radio advertising expenditure and sales values.\n",
        "\n",
        "The variables X, an array of radio values, y, an array of sales values, and predictions, an array of the model's predicted values for y given X, have all been preloaded for you from the previous exercise.\n",
        "\n",
        "Instructions\n",
        "1.  Import matplotlib.pyplot as plt.\n",
        "2.  Create a scatter plot visualizing y against X, with observations in blue.\n",
        "3.  Draw a red line plot displaying the predictions against X.\n",
        "4.  Display the plot."
      ],
      "metadata": {
        "id": "0cSbxYvgZ-QQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create scatter plot\n",
        "plt.scatter(X, y, color=\"b\")\n",
        "\n",
        "# Create line plot\n",
        "plt.plot(X, predictions, color=\"r\")\n",
        "plt.xlabel(\"Radio Expenditure ($)\")\n",
        "plt.ylabel(\"Sales ($)\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "v_KQkrezZ96W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The basics of linear regression\n",
        "\n",
        "**Regession Mechanics**\n",
        "*  y = ax + b\n",
        "*  y = target\n",
        "*  x = single feature\n",
        "*  a,b = parameters/coefficient of the model - slope/intercept\n",
        "\n",
        "**How do we choose a and b**\n",
        "*  Define an error function for any given line\n",
        "*  Choose a line that minimizes the error function\n",
        "*  Error function = loss function = cost function\n",
        "\n",
        "Residual -vertical distance between the datapoint and the line\n",
        "Ordinary Least Square (OLS): Squaring the residual thus minimizing RSS\n",
        "\n",
        "**Linear regression in high dimensions**\n",
        "y = a1x1 + a2x2 + b\n",
        "\n",
        "*To fit a linear regression model here:*\n",
        "* Need to specify 3 variables, a1,a2,b\n",
        "\n",
        "*In higher dimensions:* \n",
        "* Known as multiple regression\n",
        "* Must specify coefficients for each feature and the variable b\n",
        "* y = a1x1 + a2x2 + ... + anxn + b\n",
        "\n",
        "*scikit-learn works exactly the same way:*\n",
        "* Pass two arrays: features and target\n"
      ],
      "metadata": {
        "id": "JNA0hRzednxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear regression using all features**\n"
      ],
      "metadata": {
        "id": "gVFinyBBf2CJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model  import LinearRegression\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =0.3, random_state =42)\n",
        "reg_all = LinearRegression() \n",
        "reg_all.fit(X_train, y_train)\n",
        "y_pred = reg_all.predict(X_test)"
      ],
      "metadata": {
        "id": "5FcfMIJ2gD55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**R-squared**\n",
        "* R^2: quantifies the variance in target values explained by the features\n",
        "* Values ranges from 0 to 1\n",
        "* High R^2 = data points close to the linear regression line, more fit\n",
        "* High R^2 = data points are not close to the linear regression line\n"
      ],
      "metadata": {
        "id": "ARQ64qL8gsc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**R-squared in scikit-learn**"
      ],
      "metadata": {
        "id": "nn4tiEQthi54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg_all.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "S-Y0wx-qhl2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mean squared error and root mean squared error**\n",
        "* MSE is measured in target units, squared\n",
        "* RMSE or square of MSE is in the same unit at the target variable"
      ],
      "metadata": {
        "id": "7w2fHuRdiP4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RMSE in scikit-learn**"
      ],
      "metadata": {
        "id": "WcYOfimailkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(y_test, y_pred, squared = False)"
      ],
      "metadata": {
        "id": "9_YErdNMilCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Exercise:**Fit and predict for regression\n",
        "\n",
        "Now you have seen how linear regression works, your task is to create a multiple linear regression model using all of the features in the sales_df dataset, which has been preloaded for you. As a reminder, here are the first two rows:\n",
        "\n",
        "         tv        radio      social_media    sales\n",
        "    1    13000.0   9237.76    2409.57         46677.90\n",
        "    2    41000.0   15886.45   2913.41         150177.83\n",
        "You will then use this model to predict sales based on the values of the test features.\n",
        "\n",
        "LinearRegression and train_test_split have been preloaded for you from their respective modules.\n",
        "\n",
        "Instructions\n",
        "1. Create X, an array containing values of all features in sales_df, and y, containing all values from the \"sales\" column.\n",
        "2. Instantiate a linear regression model.\n",
        "3. Fit the model to the training data.\n",
        "4. Create y_pred, making predictions for sales using the test features."
      ],
      "metadata": {
        "id": "R85mzK8Qilix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create X and y arrays\n",
        "X = sales_df.drop(\"sales\", axis=1).values\n",
        "y = sales_df[\"sales\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Instantiate the model\n",
        "reg_all = LinearRegression() \n",
        "\n",
        "# Fit the model to the data\n",
        "reg_all.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = reg_all.predict(X_test)\n",
        "print(\"Predictions: {}, Actual Values: {}\".format(y_pred[:2], y_test[:2]))"
      ],
      "metadata": {
        "id": "M174KEtdkPvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise:** Regression performance\n",
        "Now you have fit a model, reg, using all features from sales_df, and made predictions of sales values, you can evaluate performance using some common regression metrics.\n",
        "\n",
        "The variables X_train, X_test, y_train, y_test, and y_pred, along with the fitted model, reg, all from the last exercise, have been preloaded for you.\n",
        "\n",
        "Your task is to find out how well the features can explain the variance in the target values, along with assessing the model's ability to make predictions on unseen data.\n",
        "\n",
        "Instructions\n",
        "1. Import mean_squared_error.\n",
        "2. Calculate the model's R-squared score by passing the test feature values and the test target values to an appropriate method.\n",
        "3. Calculate the model's root mean squared error using y_test and y_pred.\n",
        "4. Print r_squared and rmse."
      ],
      "metadata": {
        "id": "oFAb8zKjluKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import mean_squared_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Compute R-squared\n",
        "r_squared = reg.score(X_test,y_test)\n",
        "\n",
        "# Compute RMSE\n",
        "rmse =mean_squared_error(y_test, y_pred, squared = False)\n",
        "\n",
        "# Print the metrics\n",
        "print(\"R^2: {}\".format(r_squared))\n",
        "print(\"RMSE: {}\".format(rmse))"
      ],
      "metadata": {
        "id": "ip1h952Kl2ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Cross-validation**\n",
        "**Cross-validation motivation**\n",
        "* Model performance is dependent on the way we split up the data\n",
        "* Not representative of the model's ability to generalize unseen data\n",
        "* **Solution:** Cross-validation\n",
        "\n",
        "**5-folds Cross Validation**\n",
        "1. Splitting the dataset into 5 group/folds\n",
        "2. We set the 1st fold as the test set\n",
        "3. Fit our model on the remaining four folds, predict on our test set\n",
        "4. Compute the metric of interest such as R-squared\n",
        "5. We set aside 2nd fold as the test set and repeat 3 & 4\n",
        "6. We set aside 3rd fold as the test set and repeat 3 & 4\n",
        "7. We set aside 4th fold as the test set and repeat 3 & 4\n",
        "8. We set aside 5th fold as the test set and repeat 3 & 4\n",
        "9. Now, we have 5 values of R-squared from which we can compute statistics of interest such as mean, median, 95% confidence interval\n",
        "\n",
        "Cross validation can be:\n",
        "* 10-folds Cross Validation\n",
        "* k-folds Cross Validation\n",
        "* More folds = More computationally expensive\n",
        "\n"
      ],
      "metadata": {
        "id": "0AlA2nitneJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross-validation in scikit-learn**"
      ],
      "metadata": {
        "id": "b4pPEu33qOKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "kf =KFold(n_splits =6, shuffle= True, random_state = 42)\n",
        "reg = LinearRegression()\n",
        "cv_results = cross_val_score(reg, X, y, cv=kf)\n"
      ],
      "metadata": {
        "id": "acpe8m63qSNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluating cross-validation performance**"
      ],
      "metadata": {
        "id": "T3kD_wbJuPb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(cv_results)\n",
        "print(np.mean(cv_results),np.std(cv_results))\n",
        "print(np.quantile(cv_results, [0.025,0.975]))\n",
        "\n"
      ],
      "metadata": {
        "id": "jjTQVsv4uJMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Exercise:** Cross-validation for R-squared\n",
        "\n",
        "Cross-validation is a vital approach to evaluating a model. It maximizes the amount of data that is available to the model, as the model is not only trained but also tested on all of the available data.\n",
        "\n",
        "In this exercise, you will build a linear regression model, then use 6-fold cross-validation to assess its accuracy for predicting sales using social media advertising expenditure. You will display the individual score for each of the six-folds.\n",
        "\n",
        "The sales_df dataset has been split into y for the target variable, and X for the features, and preloaded for you. LinearRegression has been imported from sklearn.linear_model.\n",
        "\n",
        "Instructions\n",
        "1. Import KFold and cross_val_score.\n",
        "2. Create kf by calling KFold(), setting the number of splits to six, shuffle to True, and setting a seed of 5.\n",
        "3. Perform cross-validation using reg on X and y, passing kf to cv.\n",
        "4. Print the cv_scores."
      ],
      "metadata": {
        "id": "DAMiWD7ruGDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "# Create a KFold object\n",
        "kf =KFold(n_splits =6, shuffle= True, random_state = 5)\n",
        "\n",
        "reg = LinearRegression()\n",
        "\n",
        "# Compute 6-fold cross-validation scores\n",
        "cv_scores = cross_val_score(reg, X, y, cv=kf)\n",
        "\n",
        "# Print scores\n",
        "print(cv_scores)"
      ],
      "metadata": {
        "id": "hiEgcGKZutcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Exercise:** Analyzing cross-validation metrics\n",
        "Now you have performed cross-validation, it's time to analyze the results.\n",
        "\n",
        "You will display the mean, standard deviation, and 95% confidence interval for cv_results, which has been preloaded for you from the previous exercise.\n",
        "\n",
        "numpy has been imported for you as np.\n",
        "\n",
        "Instructions\n",
        "1. Calculate and print the mean of the results.\n",
        "2. Calculate and print the standard deviation of cv_results.\n",
        "3. Display the 95% confidence interval for your results using np.quantile()."
      ],
      "metadata": {
        "id": "7lZ2h_plu5rM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the mean\n",
        "print(np.mean(cv_results))\n",
        "\n",
        "# Print the standard deviation\n",
        "print(np.std(cv_results))\n",
        "\n",
        "# Print the 95% confidence interval\n",
        "print(np.quantile(cv_results, [0.025,0.975]))"
      ],
      "metadata": {
        "id": "q1QobgRfvRCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Regularized regression**\n",
        "**Why regularize?**\n",
        "* Recall: Linear Regression minimizes a loss function\n",
        "* It chooses a coefficient, a, for each feature variable, plus b\n",
        "* Large coefficients can lead to overfitting\n",
        "* Regularization: Penalize large coefficients\n",
        "\n",
        "**Ridge regression**\n",
        "* First type of regularization\n",
        "* Ridges penalizes large positive/negative coefficients\n",
        "* alpha: parameter we need to choose\n",
        "* Picking alpha is similar to picking k in KNN\n",
        "* Hyperparameter: variable used to optimize model parameters\n",
        "* Alpha controls model complexity\n",
        "* When alpha =0, can lead to overfitting\n",
        "* Very high apha, can lead to underfitting\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "95XjKZtLvtDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ridge regression in scikit-learn**"
      ],
      "metadata": {
        "id": "WaNfgtN8xEHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "score = []\n",
        "for alpha in [0.1,1.0,10.0,100.0,1000.0]:\n",
        "  ridge = Ridge(alpha=alpha)\n",
        "  ridge.fit(X_train, y_train)\n",
        "  y_pred = ridge.predict(X_test)\n",
        "  scores.append(ridge.score(X_test, y_test))\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "beCMKyzfxJWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lasso regression in scikit-learn**"
      ],
      "metadata": {
        "id": "xQC0oXpWyN1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "score = []\n",
        "for alpha in [0.01,1.0,10.0,20.0,50.0]:\n",
        "  lasso = Lasso(alpha=alpha)\n",
        "  lasso.fit(X_train, y_train)\n",
        "  lasso_pred = lasso.predict(X_test)\n",
        "  scores.append(lasso.score(X_test, y_test))\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "AjIUVy-2yZqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lasso Regression for feature selection**\n",
        "* Lasso can select important features of a dataset\n",
        "* Shrinks the coefficients of less important features to zero\n",
        "* Features not shrunk to zero are selected by lasso\n",
        "\n"
      ],
      "metadata": {
        "id": "RADvGyG_y8TZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lasso for feature selection in scikit-learn**\n"
      ],
      "metadata": {
        "id": "lALZ0Pbg1GJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "x= diabetes_df.drop(\"glucose\", axis=1).values\n",
        "y= diabetes_df[\"glucose\"].values\n",
        "name= diabetes_df.drop(\"glucose\", axis=1).columns\n",
        "lasso = Lasso(alpha=0.1)\n",
        "lasso_coef = lasso.fit(X, y).coef_\n",
        "plt.bar(names, lasso_coef)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FwhvGx601O89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Exercise:** Regularized regression: Ridge\n",
        "\n",
        "Ridge regression performs regularization by computing the squared values of the model parameters multiplied by alpha and adding them to the loss function.\n",
        "\n",
        "In this exercise, you will fit ridge regression models over a range of different alpha values, and print their R^2 scores. You will use all of the features in the sales_df dataset to predict \"sales\". The data has been split into X_train, X_test, y_train, y_test for you.\n",
        "\n",
        "A variable called alphas has been provided as a list containing different alpha values, which you will loop through to generate scores.\n",
        "\n",
        "Instructions\n",
        "1. Import Ridge.\n",
        "2. Instantiate Ridge, setting alpha equal to alpha.\n",
        "3. Fit the model to the training data.\n",
        "4. Calculate the  score for each iteration of ridge"
      ],
      "metadata": {
        "id": "ea8j45yx3yzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Ridge\n",
        "from sklearn.linear_model import Ridge\n",
        "alphas = [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
        "ridge_scores = []\n",
        "for alpha in alphas:\n",
        "  \n",
        "  # Create a Ridge regression model\n",
        "  ridge = Ridge(alpha=alpha)\n",
        "  \n",
        "  # Fit the data\n",
        "  ridge.fit(X_train, y_train)\n",
        "  \n",
        "  # Obtain R-squared\n",
        "  score = ridge.score(X_test, y_test)\n",
        "  ridge_scores.append(score)\n",
        "print(ridge_scores)"
      ],
      "metadata": {
        "id": "_AhtUJxC4Amm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Exercise:** Lasso regression for feature importance\n",
        "In the video, you saw how lasso regression can be used to identify important features in a dataset.\n",
        "\n",
        "In this exercise, you will fit a lasso regression model to the sales_df data and plot the model's coefficients.\n",
        "\n",
        "The feature and target variable arrays have been pre-loaded as X and y, along with sales_columns, which contains the dataset's feature names.\n",
        "\n",
        "Instructions\n",
        "\n",
        "1. Import Lasso from sklearn.linear_model.\n",
        "2. Instantiate a Lasso regressor with an alpha of 0.3.\n",
        "3. Fit the model to the data.\n",
        "4. Compute the model's coefficients, storing as lasso_coef."
      ],
      "metadata": {
        "id": "jwdQcl885J6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Lasso\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# Instantiate a lasso regression model\n",
        "lasso = Lasso(alpha=0.3)\n",
        "\n",
        "# Fit the model to the data\n",
        "lasso.fit(X, y)\n",
        "\n",
        "# Compute and print the coefficients\n",
        "lasso_coef = lasso.fit(X, y).coef_\n",
        "print(lasso_coef)\n",
        "plt.bar(sales_columns, lasso_coef)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cMwpOCds5v69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Fine-Tuning Your Model**\n",
        "\n",
        "**Classification of metrics**\n",
        "\n",
        "Measuring model performance with accuracy:\n",
        "* Fractio of correctly classified samples\n",
        "* Not always a useful metric\n",
        "\n",
        "**Class imbalance**\n",
        "\n",
        "Classification for predicting fraudulent bank transactions. \n",
        "* 99% are legitimate, 1% are fraudulent.\n",
        "\n",
        "Could build a classifier that predicts NONE of the transactions are fraudulent\n",
        "* 99% accurate\n",
        "* But terrible at actually predicting fraudulent transactions\n",
        "* Fails at its original purpose\n",
        "\n",
        "Class imbalance: Uneven frequency of classes\n",
        "\n",
        "Need a different way to assess performance\n",
        "\n",
        "**Confusion matrix for asessing classification performance**\n",
        "\n",
        "* **Prediction:** Fraudulent or Legitimate\n",
        "* **Actual:** Fraudulent or Legitimate\n",
        "\n",
        "---\n",
        "\n",
        "* **True Positive:** P.Fraudulent & A.Fraudulent\n",
        "* **False Positive:** P.Fraudulent & A.Legitimate\n",
        "* **False Negative:** P.Legitimate & A.Fraudulent\n",
        "* **True Negative:** P.Legitimate & A.Legitimate\n",
        "---\n",
        "* Accuracy = (True Prediction + False Prediction)/Total\n",
        "* Precision = true positives/(true positives + false positives)\n",
        "\n",
        "High Precision: lower false positive rate thus not many legitimate transactions are predicted to be fraudulent.\n",
        "* Recall = true positives/ (true positives + false negative)\n",
        "\n",
        "High Recall = lower false negative rate thus predicted most fraudulent transactions correctly. \n",
        "\n",
        "* F1 score = 2(precisions * recall)/(precision + recall)\n"
      ],
      "metadata": {
        "id": "A8kRxiL553PS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion matrix in scikit-learn**"
      ],
      "metadata": {
        "id": "RKExH64L6ZAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "knn = KNeighborsClassifier(n_neighbors =7)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "id": "Ma17DLYA6Xss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c81443-0c02-4da2-fb2f-7235083b358e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1133    5]\n",
            " [ 185   11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification report in scikit-learn**"
      ],
      "metadata": {
        "id": "PZlm1_Tf6ZGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqdykavclIqm",
        "outputId": "bd0701b7-4e1c-4c7f-f401-f714fdda2207"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.92      1138\n",
            "           1       0.69      0.06      0.10       196\n",
            "\n",
            "    accuracy                           0.86      1334\n",
            "   macro avg       0.77      0.53      0.51      1334\n",
            "weighted avg       0.83      0.86      0.80      1334\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Exercise:**Assessing a diabetes prediction classifier\n",
        "In this chapter you'll work with the diabetes_df dataset introduced previously.\n",
        "\n",
        "The goal is to predict whether or not each individual is likely to have diabetes based on the features body mass index (BMI) and age (in years). Therefore, it is a binary classification problem. A target value of 0 indicates that the individual does not have diabetes, while a value of 1 indicates that the individual does have diabetes.\n",
        "\n",
        "diabetes_df has been preloaded for you as a pandas DataFrame and split into X_train, X_test, y_train, and y_test. In addition, a KNeighborsClassifier() has been instantiated and assigned to knn.\n",
        "\n",
        "You will fit the model, make predictions on the test set, then produce a confusion matrix and classification report.\n",
        "\n",
        "Instructions\n",
        "\n",
        "1. Import confusion_matrix and classification_report.\n",
        "2. Fit the model to the training data.\n",
        "3. Predict the labels of the test set, storing the results as y_pred.\n",
        "4. Compute and print the confusion matrix and classification report for the test labels versus the predicted labels."
      ],
      "metadata": {
        "id": "AMJFt5fnnH94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=6)\n",
        "\n",
        "# Fit the model to the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test data: y_pred\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Generate the confusion matrix and classification report\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9QH93r4nRKF",
        "outputId": "b71cc8e2-3022-4f8d-8005-ec100c29f281"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1136    2]\n",
            " [ 191    5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.92      1138\n",
            "           1       0.71      0.03      0.05       196\n",
            "\n",
            "    accuracy                           0.86      1334\n",
            "   macro avg       0.79      0.51      0.49      1334\n",
            "weighted avg       0.84      0.86      0.79      1334\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic regression and the ROC curve**\n",
        "\n",
        "**Logistics Regression**\n",
        "* Used for classification problems\n",
        "* Outputs probabilities\n",
        "* If the probability, p >=0.5 the data is labeled as 1\n",
        "* If the probability, p < 0.5 the data is labeled as 0\n",
        "* Produces a linear decision boundary\n"
      ],
      "metadata": {
        "id": "w7P1WE-npdO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistics regression in scikit-learn**\n"
      ],
      "metadata": {
        "id": "ES456Vy0qBkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload dataset\n",
        "url = \"https://raw.githubusercontent.com/ShairaRubante/FTW/main/telecom_churn_clean.csv\"\n",
        "churn = pd.read_csv(url)\n",
        "display(churn.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "qBF7odJ8qMSL",
        "outputId": "684ba72d-09ff-4a7c-ef28-0dc570c23a69"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Unnamed: 0  account_length  area_code  international_plan  voice_mail_plan  \\\n",
              "0           0             128        415                   0                1   \n",
              "1           1             107        415                   0                1   \n",
              "2           2             137        415                   0                0   \n",
              "3           3              84        408                   1                0   \n",
              "4           4              75        415                   1                0   \n",
              "\n",
              "   number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
              "0                     25              265.1              110   \n",
              "1                     26              161.6              123   \n",
              "2                      0              243.4              114   \n",
              "3                      0              299.4               71   \n",
              "4                      0              166.7              113   \n",
              "\n",
              "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
              "0             45.07              197.4               99             16.78   \n",
              "1             27.47              195.5              103             16.62   \n",
              "2             41.38              121.2              110             10.30   \n",
              "3             50.90               61.9               88              5.26   \n",
              "4             28.34              148.3              122             12.61   \n",
              "\n",
              "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
              "0                244.7                 91               11.01   \n",
              "1                254.4                103               11.45   \n",
              "2                162.6                104                7.32   \n",
              "3                196.9                 89                8.86   \n",
              "4                186.9                121                8.41   \n",
              "\n",
              "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
              "0                10.0                 3               2.70   \n",
              "1                13.7                 3               3.70   \n",
              "2                12.2                 5               3.29   \n",
              "3                 6.6                 7               1.78   \n",
              "4                10.1                 3               2.73   \n",
              "\n",
              "   customer_service_calls  churn  \n",
              "0                       1      0  \n",
              "1                       1      0  \n",
              "2                       0      0  \n",
              "3                       2      0  \n",
              "4                       3      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ff6fcbe-7f59-4558-9ac3-7659ce606386\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>account_length</th>\n",
              "      <th>area_code</th>\n",
              "      <th>international_plan</th>\n",
              "      <th>voice_mail_plan</th>\n",
              "      <th>number_vmail_messages</th>\n",
              "      <th>total_day_minutes</th>\n",
              "      <th>total_day_calls</th>\n",
              "      <th>total_day_charge</th>\n",
              "      <th>total_eve_minutes</th>\n",
              "      <th>total_eve_calls</th>\n",
              "      <th>total_eve_charge</th>\n",
              "      <th>total_night_minutes</th>\n",
              "      <th>total_night_calls</th>\n",
              "      <th>total_night_charge</th>\n",
              "      <th>total_intl_minutes</th>\n",
              "      <th>total_intl_calls</th>\n",
              "      <th>total_intl_charge</th>\n",
              "      <th>customer_service_calls</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>265.1</td>\n",
              "      <td>110</td>\n",
              "      <td>45.07</td>\n",
              "      <td>197.4</td>\n",
              "      <td>99</td>\n",
              "      <td>16.78</td>\n",
              "      <td>244.7</td>\n",
              "      <td>91</td>\n",
              "      <td>11.01</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>107</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>161.6</td>\n",
              "      <td>123</td>\n",
              "      <td>27.47</td>\n",
              "      <td>195.5</td>\n",
              "      <td>103</td>\n",
              "      <td>16.62</td>\n",
              "      <td>254.4</td>\n",
              "      <td>103</td>\n",
              "      <td>11.45</td>\n",
              "      <td>13.7</td>\n",
              "      <td>3</td>\n",
              "      <td>3.70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>137</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>243.4</td>\n",
              "      <td>114</td>\n",
              "      <td>41.38</td>\n",
              "      <td>121.2</td>\n",
              "      <td>110</td>\n",
              "      <td>10.30</td>\n",
              "      <td>162.6</td>\n",
              "      <td>104</td>\n",
              "      <td>7.32</td>\n",
              "      <td>12.2</td>\n",
              "      <td>5</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>84</td>\n",
              "      <td>408</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>299.4</td>\n",
              "      <td>71</td>\n",
              "      <td>50.90</td>\n",
              "      <td>61.9</td>\n",
              "      <td>88</td>\n",
              "      <td>5.26</td>\n",
              "      <td>196.9</td>\n",
              "      <td>89</td>\n",
              "      <td>8.86</td>\n",
              "      <td>6.6</td>\n",
              "      <td>7</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>75</td>\n",
              "      <td>415</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>166.7</td>\n",
              "      <td>113</td>\n",
              "      <td>28.34</td>\n",
              "      <td>148.3</td>\n",
              "      <td>122</td>\n",
              "      <td>12.61</td>\n",
              "      <td>186.9</td>\n",
              "      <td>121</td>\n",
              "      <td>8.41</td>\n",
              "      <td>10.1</td>\n",
              "      <td>3</td>\n",
              "      <td>2.73</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ff6fcbe-7f59-4558-9ac3-7659ce606386')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ff6fcbe-7f59-4558-9ac3-7659ce606386 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ff6fcbe-7f59-4558-9ac3-7659ce606386');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX7ZgxutqOTP",
        "outputId": "d7f16cd8-6767-4105-af66-382783a706b7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicting Probabilities**"
      ],
      "metadata": {
        "id": "MN_xUgynq07s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs =logreg.predict_proba(X_test)[:,1]\n",
        "print(y_pred_probs[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38WuMS0nq0ko",
        "outputId": "2c6ddf56-8048-4dc4-cea6-1b37748ce383"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1595799285365924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Probability Threshold**\n",
        "* By default, logistic regression threshold = 0.5\n",
        "* Not specific tologistic regression, KNN classifier also have threshholds\n",
        "* What happpens if we vary thresholds?\n",
        "* We use the ROC curve to visualize how different threshold affects false positive and true negative.\n",
        "*  p=0 correctly predict positive value and incorrectly predict negative values\n",
        "*  p= 1 both true and false is 0\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TqjqaainrJC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting the ROC curve**"
      ],
      "metadata": {
        "id": "juxOmPaMr43c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Logistics Regression ROC Curve\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "kPYy8yWur8A0",
        "outputId": "a14d3bca-dc14-4f5a-ea88-530d37eb1460"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC AUC in scikit-learn**"
      ],
      "metadata": {
        "id": "d5W6B3Yss0DV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "print(roc_auc_score(y_test, y_pred_probs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6SyhuHZs5qt",
        "outputId": "8066fe9c-5ec5-49c2-e2a4-e05ee35e4d20"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7323889645943322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Exercise:** ROC AUC\n",
        "The ROC curve you plotted in the last exercise looked promising.\n",
        "\n",
        "Now you will compute the area under the ROC curve, along with the other classification metrics you have used previously.\n",
        "\n",
        "The confusion_matrix and classification_report functions have been preloaded for you, along with the logreg model you previously built, plus X_train, X_test, y_train, y_test. Also, the model's predicted test set labels are stored as y_pred, and probabilities of test set observations belonging to the positive class stored as y_pred_probs.\n",
        "\n",
        "A knn model has also been created and the performance metrics printed in the console, so you can compare the roc_auc_score, confusion_matrix, and classification_report between the two models.\n",
        "\n",
        "Instructions\n",
        "* Import roc_auc_score.\n",
        "* Calculate and print the ROC AUC score, passing the test labels and the predicted positive class probabilities.\n",
        "* Calculate and print the confusion matrix.\n",
        "* Call classification_report()."
      ],
      "metadata": {
        "id": "crSVk49suFvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import roc_auc_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Calculate roc_auc_score\n",
        "print(roc_auc_score(y_test, y_pred_probs))\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Calculate the classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qXEBSa8uQ_F",
        "outputId": "42739b54-0094-463c-f305-076eec520150"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7323889645943322\n",
            "[[856   1]\n",
            " [139   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.92       857\n",
            "           1       0.80      0.03      0.05       143\n",
            "\n",
            "    accuracy                           0.86      1000\n",
            "   macro avg       0.83      0.51      0.49      1000\n",
            "weighted avg       0.85      0.86      0.80      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Hyperparameter tuning**\n",
        "\n",
        "**Hyperparameter tuning**\n",
        "* Ridge/lasso regression: Choosing alpha\n",
        "* KNN: Choosing neighbors\n",
        "* Hyperparameters: Paramters we specify before fitting the models like alpha and n_neighbors\n",
        "\n",
        "**Choosing the correct hyperparameter**\n",
        "1. Try lots of different hyperparameter values\n",
        "2. Fit all of them separately\n",
        "3. See how well they perform\n",
        "4. Choose the best performing values\n",
        "\n",
        "* This is called hyperparameter tuning\n",
        "* It is essential to use cross-validation to avoid overfitting to the test set\n",
        "* We can still split the data and perform cross-validation on the training set\n",
        "* We withhold the test set to final evaluation\n",
        "\n",
        "**Grid search validation**\n",
        "Use grid and choose which hyperparameter perform best\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aKrPh9ECubf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GridSearchCV in scikit-learn**"
      ],
      "metadata": {
        "id": "HvFH6pRQ3obv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload dataset\n",
        "url = \"https://raw.githubusercontent.com/ShairaRubante/FTW/main/telecom_churn_clean.csv\"\n",
        "churn = pd.read_csv(url)\n",
        "display(churn.head())"
      ],
      "metadata": {
        "id": "M3cP_0LBupCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "param_grid ={\"alpha\":np.arange(0.0001,10),\"solver\":[\"sag\",\"lsqr\"]}\n",
        "ridge =Ridge()\n",
        "ridge_cv =GridSearchCV(ridge, param_grid, cv=kf)\n",
        "ridge_cv.fit(X_train,y_train)\n",
        "print(ridge_cv.best_params_,ridge_cv.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Rqmn2Sm3w42",
        "outputId": "6a74458f-d497-480a-898c-cf9645391f36"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'alpha': 0.0001, 'solver': 'sag'} 0.09008824233417875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Limitation and an alternative approach**\n",
        "* 3-fold cross-validation, 1 hyperparameter, 10 total values = 30 fits\n",
        "* 10-fold cross-validation, 3 hyperparameter, 30 total values = 900 fits"
      ],
      "metadata": {
        "id": "InFoWxI743xE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RandomizedSearchCV**"
      ],
      "metadata": {
        "id": "HGxmNz6z3ohk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "param_grid ={\"alpha\":np.arange(0.0001,1,10),\"solver\":[\"sag\",\"lsqr\"]}\n",
        "ridge =Ridge()\n",
        "ridge_cv =RandomizedSearchCV(ridge, param_grid, cv=kf, n_iter=2)\n",
        "ridge_cv.fit(X_train,y_train)\n",
        "print(ridge_cv.best_params_,ridge_cv.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCJ-l2B35PtE",
        "outputId": "3c255dbc-4592-4b47-9652-d0b692b6f1dc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'solver': 'sag', 'alpha': 0.0001} 0.0900905793235575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluating on the test set**"
      ],
      "metadata": {
        "id": "Li5lKvAi5xxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = ridge_cv.score(X_test, y_test)\n",
        "print(test_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxGQoSKZ50t0",
        "outputId": "c82c0af0-6ee2-47e2-fcd6-26cf939cfc92"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12199266932081398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter tuning with RandomizedSearchCV**\n",
        "\n",
        "As you saw, GridSearchCV can be computationally expensive, especially if you are searching over a large hyperparameter space. In this case, you can use RandomizedSearchCV, which tests a fixed number of hyperparameter settings from specified probability distributions.\n",
        "\n",
        "Training and test sets from diabetes_df have been pre-loaded for you as X_train. X_test, y_train, and y_test, where the target is \"diabetes\". A logistic regression model has been created and stored as logreg, as well as a KFold variable stored as kf.\n",
        "\n",
        "You will define a range of hyperparameters and use RandomizedSearchCV, which has been imported from sklearn.model_selection, to look for optimal hyperparameters from these options.\n",
        "\n",
        "Instructions\n",
        "* Create params, adding \"l1\" and \"l2\" as penalty values, setting C to a range of 50 float values between 0.1 and 1.0, and class_weight to either \"balanced\" or a dictionary containing 0:0.8, 1:0.2.\n",
        "* Create the Randomized Search CV object, passing the model and the parameters, and setting cv equal to kf.\n",
        "* Fit logreg_cv to the training data.\n",
        "* Print the model's best parameters and accuracy score."
      ],
      "metadata": {
        "id": "r-6BsWRt712T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the parameter space\n",
        "params = {\"penalty\": [\"l1\", \"l2\"],\n",
        "         \"tol\": np.linspace(0.0001, 1.0, 50),\n",
        "         \"C\": np.linspace(0.1, 1.0, 50),\n",
        "         \"class_weight\": [\"balanced\", {0:0.8, 1:0.2}]}\n",
        "\n",
        "# Instantiate the RandomizedSearchCV object\n",
        "logreg_cv = RandomizedSearchCV(logreg, params, cv=kf)\n",
        "\n",
        "# Fit the data to the model\n",
        "logreg_cv.fit(X_train, y_train)\n",
        "\n",
        "# Print the tuned parameters and score\n",
        "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
        "print(\"Tuned Logistic Regression Best Accuracy Score: {}\".format(logreg_cv.best_score_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiTKGTfU8AkU",
        "outputId": "4cf5b9fc-994e-403d-897f-004e0210f44b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "30 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "30 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.64853462 0.85425738        nan        nan        nan\n",
            "        nan 0.6288151  0.64511309        nan]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned Logistic Regression Parameters: {'tol': 0.4082224489795918, 'penalty': 'l2', 'class_weight': {0: 0.8, 1: 0.2}, 'C': 1.0}\n",
            "Tuned Logistic Regression Best Accuracy Score: 0.8542573820661514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    }
  ]
}